# ğŸš— Vehicle Speed Detection System

This project implements a **Vehicle Speed Detection System** that detects, tracks, and estimates the speed of multiple vehicles from recorded traffic footage using deep learning and computer vision.  
It combines **YOLOv8** for vehicle detection, **DeepSORT** for multi-object tracking, and **OpenCV** for visualization and speed estimation.

---

## ğŸ¯ Project Overview

Modern traffic monitoring systems rely heavily on visual data.  
This project demonstrates a **data-driven computer vision pipeline** capable of:

- Detecting moving vehicles in a given video
- Tracking each vehicle with a unique ID
- Estimating and displaying the real-world speed (km/h) on bounding boxes

Built for **Google Colab**, this version provides a visual, reproducible workflow that integrates deep learning, tracking, and perspective-aware motion analysis.

---

## ğŸ§  Key Features

âœ… **Vehicle Detection** â€” Uses pretrained [YOLOv8](https://github.com/ultralytics/ultralytics) (by Ultralytics) for high-accuracy detection of cars, buses, trucks, and bikes.  
âœ… **Multi-Object Tracking** â€” Integrates [DeepSORT](https://github.com/nwojke/deep_sort) for consistent ID assignment across frames.  
âœ… **Speed Estimation** â€” Calculates speed using pixel displacement, video FPS, and a perspective-based pixel-to-meter conversion gradient.  
âœ… **Confidence Filtering** â€” Ignores weak detections below a configurable confidence threshold.  
âœ… **Perspective Correction** â€” Reduces speed distortion as vehicles move toward or away from the camera.  
âœ… **Visualization** â€” Displays bounding boxes, track IDs, and live speed (km/h) overlays in the output video.

---

## ğŸ§© Technologies Used

| Component | Purpose |
|------------|----------|
| **Python 3.10+** | Core language |
| **YOLOv8 (Ultralytics)** | Vehicle detection |
| **DeepSORT** | Object tracking |
| **OpenCV** | Frame processing and visualization |
| **NumPy** | Numerical operations |
| **Google Colab** | Cloud execution environment |

---

## âš™ï¸ System Architecture

```plaintext
Input Video
   â”‚
   â–¼
YOLOv8 Detector â†’ Bounding Boxes
   â”‚
   â–¼
DeepSORT Tracker â†’ Vehicle IDs & Paths
   â”‚
   â–¼
Speed Estimation (Pixel â†’ Meter â†’ km/h)
   â”‚
   â–¼
OpenCV Visualization â†’ Bounding Boxes + Speed Overlay
   â”‚
   â–¼
Output Video (output_fixed.avi)
```

---

## ğŸ§ª Implementation Steps

The Colab implementation is structured into three main stages:

### 1ï¸âƒ£ Vehicle Detection
- Load a pretrained YOLOv8 model (`yolov8n.pt`)
- Run detection on each frame of the uploaded traffic video
- Apply confidence filtering to reduce noise

### 2ï¸âƒ£ Multi-Object Tracking
- Initialize a DeepSORT tracker
- Track multiple vehicles across frames while maintaining unique IDs

### 3ï¸âƒ£ Speed Estimation
- Compute pixel displacement between consecutive frames
- Apply a perspective-aware conversion (pixel â†’ meter)
- Calculate real-world speeds using frame rate (FPS)
- Overlay smoothed speed values on each bounding box

---

## ğŸ§® Speed Estimation Model

The pixel-to-meter ratio varies with depth in the scene:

\[
\text{meters_per_pixel}(y) = m_{far} + (m_{near} - m_{far}) \times \frac{y}{H}
\]

where  
- \( y \): vertical pixel coordinate  
- \( H \): frame height  
- \( m_{far}, m_{near} \): conversion factors for far and near regions

Speed is then computed as:

\[
v_{km/h} = \text{distance}_{pixels} \times \text{meters\_per\_pixel} \times FPS \times 3.6
\]

---

## ğŸ“ˆ Results

- Each detected vehicle is assigned a **unique ID**.
- The bounding box displays **smoothed real-world speed** in km/h.
- Perspective correction eliminates drastic speed fluctuations when vehicles approach or recede from the camera.
- The processed video is saved as **`output_fixed.avi`**.

Example output frame:  

![Sample Output Frame](https://via.placeholder.com/800x450?text=Vehicle+Speed+Detection+Example)

---

## ğŸ§° How to Run (on Google Colab)

1. Open a new Colab notebook  
2. Copy and paste the project code  
3. Run all cells sequentially  
4. Upload your input video when prompted  
5. The processed video (`output_fixed.avi`) will be generated and displayed inline

---

## âš™ï¸ Adjustable Parameters

| Variable | Description | Typical Value |
|-----------|--------------|----------------|
| `CONF_THRESH` | Minimum confidence for detection | 0.4 â€“ 0.6 |
| `p_far` | Meters per pixel at top of frame | 0.05 â€“ 0.08 |
| `p_near` | Meters per pixel at bottom of frame | 0.01 â€“ 0.03 |
| `SMOOTH_FRAMES` | Frames to average speed | 3 â€“ 7 |

---

## ğŸ”® Future Enhancements

- Automatic **camera calibration** using homography or known lane markers  
- Integration with **ByteTrack** for more stable ID tracking  
- Deployment via **Streamlit** for real-time visualization  
- Improved accuracy using **YOLOv8m/l** models

---

**License:** MIT  
Â© 2025 Neev Jain. All rights reserved.
